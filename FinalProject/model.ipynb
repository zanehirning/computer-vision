{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project CS5680"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programatically Making the Classes\n",
    "The JAFFE dataset did not have the classes made for me. I had to programatically go through and add them to a class. This code does just that. This code is dependent on your file structure and will not work for anyone without the correct file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# programatically make the classes\n",
    "image_directory = 'JAFFE/jaffedbase/jaffedbase'\n",
    "happy_directory = 'JAFFE/happy'\n",
    "angry_directory = 'JAFFE/angry'\n",
    "sad_directory = 'JAFFE/sad'\n",
    "surprised_directory = 'JAFFE/surprised'\n",
    "disgusted_directory = 'JAFFE/disgusted'\n",
    "fearful_directory = 'JAFFE/fearful'\n",
    "neutral_directory = 'JAFFE/neutral'\n",
    "\n",
    "for directory in [happy_directory, angry_directory, sad_directory, surprised_directory, disgusted_directory, fearful_directory, neutral_directory]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "for filename in os.listdir(image_directory):\n",
    "    if 'HA' in filename:\n",
    "        source_path = image_directory + '/' + filename\n",
    "        destination_path = happy_directory + '/' + filename\n",
    "        shutil.move(source_path, destination_path)\n",
    "    elif 'AN' in filename:\n",
    "        source_path = image_directory + '/' + filename\n",
    "        destination_path = angry_directory + '/' + filename\n",
    "        shutil.move(source_path, destination_path)\n",
    "    elif 'SA' in filename:\n",
    "        source_path = image_directory + '/' + filename\n",
    "        destination_path = sad_directory + '/' + filename\n",
    "        shutil.move(source_path, destination_path)\n",
    "    elif 'SU' in filename:\n",
    "        source_path = image_directory + '/' + filename\n",
    "        destination_path = surprised_directory + '/' + filename\n",
    "        shutil.move(source_path, destination_path)\n",
    "    elif 'DI' in filename:\n",
    "        source_path = image_directory + '/' + filename\n",
    "        destination_path = disgusted_directory + '/' + filename\n",
    "        shutil.move(source_path, destination_path)\n",
    "    elif 'FE' in filename:\n",
    "        source_path = image_directory + '/' + filename\n",
    "        destination_path = fearful_directory + '/' + filename\n",
    "        shutil.move(source_path, destination_path)\n",
    "    elif 'NE' in filename:\n",
    "        source_path = image_directory + '/' + filename\n",
    "        destination_path = neutral_directory + '/' + filename\n",
    "        shutil.move(source_path, destination_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert .tiff to .png\n",
    "This step of preprocessing was necessary because tensorflow's image_dataset_from_directory relies on it being a certain format.\n",
    "\n",
    "The output of this contained an error because I was looking at the file. I just removed this .tiff file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing your TIFF images\n",
    "classes = ['happy', 'angry', 'sad', 'surprised', 'disgusted', 'fearful', 'neutral']\n",
    "for class_name in classes:\n",
    "    tiff_directory = 'JAFFE/' + class_name\n",
    "\n",
    "    # # Path to the directory where you want to save the PNG images\n",
    "    png_directory = 'JAFFE/' + class_name\n",
    "\n",
    "    # Create the PNG directory if it doesn't exist\n",
    "    os.makedirs(png_directory, exist_ok=True)\n",
    "\n",
    "    # Iterate through each TIFF file in the directory\n",
    "    for tiff_filename in os.listdir(tiff_directory):\n",
    "        if tiff_filename.endswith('.tiff') or tiff_filename.endswith('.tif'):\n",
    "            tiff_path = os.path.join(tiff_directory, tiff_filename)\n",
    "\n",
    "            # Open the TIFF image using Pillow\n",
    "            tiff_image = Image.open(tiff_path)\n",
    "\n",
    "            # Convert and save the image as PNG\n",
    "            png_filename = os.path.splitext(tiff_filename)[0] + '.png'\n",
    "            png_path = os.path.join(png_directory, png_filename)\n",
    "            tiff_image.save(png_path, format='PNG')\n",
    "            tiff_image.close()\n",
    "            os.remove(tiff_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('JAFFE', color_mode='grayscale', image_size=(256, 256), batch_size=4, shuffle=True) #change batch size after testing\n",
    "data_iterator = data.as_numpy_iterator()\n",
    "data_batch = next(data_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the face and resize image\n",
    "In the paper, they got the face and resized the image. The following commented out code was my original attempt. However, I was spending too much time on it, so I just continued without it. From here, I can either get this implementation working, or I can just manually slice out the needed pixels. I could do this programatically because each of the images are relatively similar. The face is always in the same rough position.\n",
    "\n",
    "Regardless, this WILL be completed before I move too far onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the face and resize the image\n",
    "def segment_face(data_batch):\n",
    "    top, bottom, left, right = 16, 16, 48, 48\n",
    "\n",
    "    height, width, channels = data_batch[0].shape\n",
    "\n",
    "    face_images = []\n",
    "\n",
    "    for image in data_batch:\n",
    "        segmented_image = np.array(image[top:height-bottom, left:width-right])\n",
    "        segmented_image = cv2.UMat(segmented_image)\n",
    "        face_image = cv2.resize(segmented_image, (128, 128))\n",
    "        face_image = cv2.UMat.get(face_image)\n",
    "        face_images.append(face_image)\n",
    "\n",
    "    return tf.convert_to_tensor(face_images)\n",
    "\n",
    "data_segmented = data.map(lambda x, y: (tf.py_function(segment_face, [x], [tf.float32]), y))\n",
    "data_segmented_iterator = data_segmented.as_numpy_iterator()\n",
    "data_segmented_batch = next(data_segmented_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Piecing out the image\n",
    "In the paper, after they found the face, they pieced out the image in order to continue with their method. This is what this section of code is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide each image into pieces\n",
    "piece_size = 32\n",
    "def divide_image(image):\n",
    "    divided_images = []\n",
    "    for k in range(0, image.shape[0]):\n",
    "        batch_image_divided = []\n",
    "        for i in range(0, image.shape[1], piece_size):\n",
    "            for j in range(0, image.shape[2], piece_size):\n",
    "                divided_image = image[k, i:i+piece_size, j:j+piece_size]\n",
    "                batch_image_divided.append(divided_image)\n",
    "        divided_images.append(batch_image_divided)\n",
    "    return tf.convert_to_tensor(divided_images)\n",
    "\n",
    "data_divided = data_segmented.map(lambda x, y: (tf.py_function(divide_image, [x[0]], [tf.float32]), y))\n",
    "data_divided_iterator = data_divided.as_numpy_iterator()\n",
    "data_divided_batch = next(data_divided_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The proposed texture based transformation\n",
    "In the paper, they perform 5 levels of graph based texture transformation. So far, the below code has only done one. The graph based texture transformation utilizes a \"sigmoid\" function. This function takes two parameters, a and b, and returns 0 if a is less than b, otherwise it returns 1. The parameter \"a\" is the pixel that you are \"on\"/looking at. It gets compared with the parameter b, which is the pixel you are comparing to. In the first level graph based texture transformation, you utilize two graphs. You also utilize a kernel size, for mine, I just did a 3x3 kernel/window. The first graph takes the middle pixel in the window (the start pixel/pixel you are looking at is in the top left) and compares it to each of the other pixels. It first compares it with the top left, then top middle, then top right, then right, so on and so forth in a circle/square. This binary coding is then preserved. The second graph takes the top left pixel, or the start, and compares it to its right neighbor. The right neighbor is then compared with its right neighbor. That neighbor is compared with the neighbor below it. This graph essentially starts that the top left, and makes a comparison in a square like formation. The paper has a very great visual on this for more information. \n",
    "\n",
    "This is the first major research component in the paper. This component is supposed to be very helpful when removing necessary features. It is worth noting that in the paper, they tested 3x3, 5x5, and 7x7 graphs, in my implementation, I have only used a 3x3. This could be a potential change in my method that may help or decrease my model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The propose texture based transformation\n",
    "#a is the one youre on, b is the one youre comparing to\n",
    "def sigmoid(a, b):\n",
    "    return int(a<b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First Level Graph Based Texture Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was for testing. It should not be run in production unless desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_based_level_one_transformation(image):\n",
    "    #i, j is top left of kernel\n",
    "    # for 3x3 kernel\n",
    "    batch_binary_features = []\n",
    "    image_array = image\n",
    "    for k in range(0, image_array.shape[0]): #for each image in the batch\n",
    "        for c in range(0, image_array.shape[1]): # for each division of the image\n",
    "            binary_features = []\n",
    "            for i in range(0, image_array.shape[2] - 2, 3):\n",
    "                for j in range(0, image_array.shape[3] - 2, 3):\n",
    "                    features_one = [\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i, j]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i, j+1]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i+1, j]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i+1, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i+2, j]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i+2, j+1]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i+2, j+2]),\n",
    "                    ]\n",
    "\n",
    "                    features_two = [\n",
    "                        sigmoid(image_array[k, c, i, j], image_array[k, c, i, j+1]),\n",
    "                        sigmoid(image_array[k, c, i, j+1], image_array[k, c, i, j+2]),\n",
    "                        sigmoid(image_array[k, c, i, j+2], image_array[k, c, i+1, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+2], image_array[k, c, i+2, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+2, j+2], image_array[k, c, i+2, j+1]),\n",
    "                        sigmoid(image_array[k, c, i+2, j+1], image_array[k, c, i+2, j]),\n",
    "                        sigmoid(image_array[k, c, i+2, j], image_array[k, c, i+1, j]),\n",
    "                        sigmoid(image_array[k, c, i+1, j], image_array[k, c, i, j])         \n",
    "                    ]\n",
    "\n",
    "                    binary_features.append(features_one+features_two)\n",
    "            combined_binary_features = tf.concat([tf.convert_to_tensor(binary_features, dtype=tf.float32)], axis=-1)\n",
    "        batch_binary_features.append(combined_binary_features)\n",
    "    tf.cast(batch_binary_features, tf.float32)\n",
    "    return tf.convert_to_tensor(batch_binary_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was for testing. It should not be run in production unless desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_one_binary_features = data_divided.map(lambda x, y: (tf.py_function(graph_based_level_one_transformation, [x[0]], tf.float32), y))\n",
    "level_one_binary_features_iterator = level_one_binary_features.as_numpy_iterator()\n",
    "try:\n",
    "    level_one_binary_features_batch = next(level_one_binary_features_iterator)\n",
    "except StopIteration:\n",
    "    print(\"End of iterator reached.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "level_one_binary_features_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Checkpoint 1 Comments\n",
    "At this point in the implementation, I have only completed data loading and preprocessing. There was some difficulties with recognizing the face and segmenting the image. I will end up going back and fixing this by next checkpoint. \n",
    "\n",
    "This checkpoint, I completed my data loading and preprocessing (for the most part). I also started on one of, if not the most, major aspect of this paper/implementation. By next checkpoint, I hope to have completed the graph based texture transformation and moved onto the next major aspect. After that major aspect, the only thing left is to train the model and measure it's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Second Level Graph Based Texture Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second level graph based texture transformation, you utilize four graphs. I continued to utilize a 3x3 kernel/window. All of these graphs are slight modification of the first graph. The first graph is in the shape of a pentagon. It starts that the top pixel (the point of the pentagon). It compares this pixiel with the next one on the pentagon (down and left). It continues around the pentagon until it reaches the top pixel again. The secondg graph is the same as the first, except the pentagon is rotated -90 or 270 degrees. The tip is now at the left pixel. The third graph is the same as the first, except the pentagon is rotated 180 or -180 degrees. The tip is now at the bottom pixel. The fourth graph is the same as the first, except the pentagon is rotated 90 or -270 degrees. The tip is now at the right pixel. \n",
    "\n",
    "The actual operations are the same as the first level graph based texture transformation. It utilizes the sigmoid function from above. The main difference between these two levels is the shape of the graphs and the number of binary features it extracts. This level extracts 20 binary features. The paper has a very great visual on this for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was for testing. It should not be run in production unless desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_based_level_two_transformation(image):\n",
    "    #i, j is top left of kernel\n",
    "    # for 3x3 kernel\n",
    "    batch_binary_features = []\n",
    "    image_array = image\n",
    "    for k in range(0, image_array.shape[0]): #for each image in the batch\n",
    "        for c in range(0, image_array.shape[1]): # for each division of the image\n",
    "            binary_features = []\n",
    "            for i in range(0, image_array.shape[2] - 2, 3):\n",
    "                for j in range(0, image_array.shape[3] - 2, 3):\n",
    "                    features_one = [\n",
    "                        sigmoid(image_array[k, c, i, j+1], image_array[k, c, i+1, j]),\n",
    "                        sigmoid(image_array[k, c, i+1, j], image_array[k, c, i+2, j]),\n",
    "                        sigmoid(image_array[k, c, i+2, j], image_array[k, c, i+2, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+2, j+2], image_array[k, c, i+1, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+2], image_array[k, c, i, j+1]),\n",
    "                    ]\n",
    "                    \n",
    "                    features_two = [\n",
    "                        sigmoid(image_array[k, c, i+1, j], image_array[k, c, i, j+1]),\n",
    "                        sigmoid(image_array[k, c, i, j+1], image_array[k, c, i, j+2]),\n",
    "                        sigmoid(image_array[k, c, i, j+2], image_array[k, c, i+2, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+2, j+2], image_array[k, c, i+1, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+2], image_array[k, c, i+2, j+1]),\n",
    "                    ]\n",
    "                    \n",
    "                    features_three = [\n",
    "                        sigmoid(image_array[k, c, i+2, j+1], image_array[k, c, i+1, j]),\n",
    "                        sigmoid(image_array[k, c, i+1, j], image_array[k, c, i, j]),\n",
    "                        sigmoid(image_array[k, c, i, j], image_array[k, c, i, j+2]),\n",
    "                        sigmoid(image_array[k, c, i, j+2], image_array[k, c, i+1, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+2], image_array[k, c, i+2, j+1]),\n",
    "                    ]\n",
    "                \n",
    "                    features_four = [\n",
    "                        sigmoid(image_array[k, c, i+1, j+2], image_array[k, c, i, j+1]),\n",
    "                        sigmoid(image_array[k, c, i, j+1], image_array[k, c, i, j]),\n",
    "                        sigmoid(image_array[k, c, i, j], image_array[k, c, i+2, j]),\n",
    "                        sigmoid(image_array[k, c, i+2, j], image_array[k, c, i+2, j+1]),\n",
    "                        sigmoid(image_array[k, c, i+2, j+1], image_array[k, c, i+1, j+2]),\n",
    "                    ]\n",
    "\n",
    "                    binary_features.append(features_one+features_two+features_three+features_four)\n",
    "            combined_binary_features = tf.concat([tf.convert_to_tensor(binary_features, dtype=tf.float32)], axis=-1)\n",
    "        batch_binary_features.append(combined_binary_features)\n",
    "    tf.cast(batch_binary_features, tf.float32)\n",
    "    return tf.convert_to_tensor(batch_binary_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was for testing. It should not be run in production unless desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_two_binary_features = data_divided.map(lambda x, y: (tf.py_function(graph_based_level_two_transformation, [x[0]], tf.float32), y))\n",
    "# level_two_binary_features = level_two_binary_features.map(lambda x, y: (tf.convert_to_tensor(x), y))\n",
    "level_two_binary_features_iterator = level_two_binary_features.as_numpy_iterator()\n",
    "try:\n",
    "    level_two_binary_features_batch = next(level_two_binary_features_iterator)\n",
    "except StopIteration:\n",
    "    print(\"End of iterator reached.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "level_two_binary_features_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Third Level Graph Based Texture Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the third level graph based texture transformation, you utilize two graphs. I continued to utilize a 3x3 kernel/window. The first graph of this level is in a diamond shape. It starts at the left pixel. This pixel is compared to the pixel to the right of it (top pixel). It follows this order all the way around the diamond. This will result in 4 binary features. The second graph starts at the center pixel. It compares it to all of the diagonals. This will result in 4 binary features. Once again, the paper has a very great visual on this for more information. This will result in 8 binary features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was for testing. It should not be run in production unless desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_based_level_three_transformation(image):\n",
    "    #i, j is top left of kernel\n",
    "    # for 3x3 kernel\n",
    "    batch_binary_features = []\n",
    "    image_array = image\n",
    "    for k in range(0, image_array.shape[0]): #for each image in the batch\n",
    "        for c in range(0, image_array.shape[1]): # for each division of the image\n",
    "            binary_features = []\n",
    "            for i in range(0, image_array.shape[2] - 2, 3):\n",
    "                for j in range(0, image_array.shape[3] - 2, 3):\n",
    "                    features_one = [\n",
    "                        sigmoid(image_array[k, c, i+1, j], image_array[k, c, i, j+1]),\n",
    "                        sigmoid(image_array[k, c, i, j+1], image_array[k, c, i+1, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+2], image_array[k, c, i+2, j+1]),\n",
    "                        sigmoid(image_array[k, c, i+2, j+1], image_array[k, c, i+1, j]),\n",
    "                    ]\n",
    "                    \n",
    "                    features_two = [\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i, j]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i+2, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i+1, j]),\n",
    "                    ]\n",
    "\n",
    "                    binary_features.append(features_one+features_two)\n",
    "            combined_binary_features = tf.concat([tf.convert_to_tensor(binary_features, dtype=tf.float32)], axis=-1)\n",
    "        batch_binary_features.append(combined_binary_features)\n",
    "    tf.cast(batch_binary_features, tf.float32)\n",
    "    return tf.convert_to_tensor(batch_binary_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was for testing. It should not be run in production unless desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_three_binary_features = data_divided.map(lambda x, y: (tf.py_function(graph_based_level_three_transformation, [x[0]], tf.float32), y))\n",
    "# level_three_binary_features = level_three_binary_features.map(lambda x, y: (tf.convert_to_tensor(x), y))\n",
    "level_three_binary_features_iterator = level_three_binary_features.as_numpy_iterator()\n",
    "try:\n",
    "    level_three_binary_features_batch = next(level_three_binary_features_iterator)\n",
    "except StopIteration:\n",
    "    print(\"End of iterator reached.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "level_three_binary_features_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fourth Level Graph Based Texture Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the fourth level graph based texture transformation, you utilize four graphs. Once again, I utilized a 3x3 kernel size. The first graph is in the shape of a triangle. It compares the top pixel with the bottom right pixel. It then compares the bottom right pixel with the bottom left pixel. This will result in 3 binary features being extracted. The second graph is an altered version of the first. This graph is still the triangle shape, but it is rotated -90 or 270 degrees. The third graph is an altered version of the first. This graph is still the triangle shape, but it is rotated 180 or -180 degrees. The fourth graph is an altered version of the first. This graph is still the triangle shape, but it is rotated 90 or -270 degrees. This will result in 12 binary features being extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was for testing. It should not be run in production unless desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_based_level_four_transformation(image):\n",
    "    #i, j is top left of kernel\n",
    "    # for 3x3 kernel\n",
    "    batch_binary_features = []\n",
    "    image_array = image\n",
    "    for k in range(0, image_array.shape[0]): #for each image in the batch\n",
    "        for c in range(0, image_array.shape[1]): # for each division of the image\n",
    "            binary_features = []\n",
    "            for i in range(0, image_array.shape[2] - 2, 3):\n",
    "                for j in range(0, image_array.shape[3] - 2, 3):\n",
    "                    features_one = [\n",
    "                        sigmoid(image_array[k, c, i+2, j], image_array[k, c, i, j+1]),\n",
    "                        sigmoid(image_array[k, c, i, j+1], image_array[k, c, i+2, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+2, j+2], image_array[k, c, i+2, j]),\n",
    "                    ]\n",
    "                    \n",
    "                    features_two = [\n",
    "                        sigmoid(image_array[k, c, i+1, j], image_array[k, c, i, j+2]),\n",
    "                        sigmoid(image_array[k, c, i, j+2], image_array[k, c, i+2, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+2, j+2], image_array[k, c, i+1, j]),\n",
    "                    ]\n",
    "                    \n",
    "                    features_three = [\n",
    "                        sigmoid(image_array[k, c, i, j], image_array[k, c, i, j+2]),\n",
    "                        sigmoid(image_array[k, c, i, j+2], image_array[k, c, i+2, j+1]),\n",
    "                        sigmoid(image_array[k, c, i+2, j+1], image_array[k, c, i, j]),\n",
    "                    ]\n",
    "                \n",
    "                    features_four = [\n",
    "                        sigmoid(image_array[k, c, i, j], image_array[k, c, i+2, j]),\n",
    "                        sigmoid(image_array[k, c, i+2, j], image_array[k, c, i+1, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+2], image_array[k, c, i, j]),\n",
    "                    ]\n",
    "\n",
    "                    binary_features.append(features_one+features_two+features_three+features_four)\n",
    "            combined_binary_features = tf.concat([tf.convert_to_tensor(binary_features, dtype=tf.float32)], axis=-1)\n",
    "        batch_binary_features.append(combined_binary_features)\n",
    "    tf.cast(batch_binary_features, tf.float32)\n",
    "    return tf.convert_to_tensor(batch_binary_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was for testing. It should not be run in production unless desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_four_binary_features = data_divided.map(lambda x, y: (tf.py_function(graph_based_level_four_transformation, [x[0]], tf.float32), y))\n",
    "# level_four_binary_features = level_four_binary_features.map(lambda x, y: (tf.convert_to_tensor(x), y))\n",
    "level_four_binary_features_iterator = level_four_binary_features.as_numpy_iterator()\n",
    "try:\n",
    "    level_four_binary_features_batch = next(level_four_binary_features_iterator)\n",
    "except StopIteration:\n",
    "    print(\"End of iterator reached.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "level_four_binary_features_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fifth Level Graph Based Texture Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fifth and final level graph based texture transformation utilizes three different graphs. The first of the three graphs compares all the pixels in a line. It compares the top left pixel with the bottom left, the top pixel with the bottom pixel, and the top right pixel with the bottom left pixel. This graph extracts 3 binary features. The second graph compares in a horizontal line. The top left pixel is compared with the top right, the left pixel is compared with the right pixel, the bottom left pixel is compared with the bottom right pixel. This graph extracts 3 binary features. The third graph compares in a diagonal line. The top left pixel is compared with the bottom right pixel, the top right pixel is compared with the bottom left pixel. This graph extracts 2 binary features. This will result in 8 binary features being extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was for testing. It should not be run in production unless desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_based_level_five_transformation(image):\n",
    "    #i, j is top left of kernel\n",
    "    # for 3x3 kernel\n",
    "    batch_binary_features = []\n",
    "    image_array = image\n",
    "    for k in range(0, image_array.shape[0]): #for each image in the batch\n",
    "        for c in range(0, image_array.shape[1]): # for each division of the image\n",
    "            binary_features = []\n",
    "            for i in range(0, image_array.shape[2] - 2, 3):\n",
    "                for j in range(0, image_array.shape[3] - 2, 3):\n",
    "                    features_one = [\n",
    "                        sigmoid(image_array[k, c, i, j], image_array[k, c, i+2, j]),\n",
    "                        sigmoid(image_array[k, c, i, j+1], image_array[k, c, i+2, j+1]),\n",
    "                        sigmoid(image_array[k, c, i, j+2], image_array[k, c, i+2, j+2]),\n",
    "                    ]\n",
    "                    \n",
    "                    features_two = [\n",
    "                        sigmoid(image_array[k, c, i, j], image_array[k, c, i, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j], image_array[k, c, i+1, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+2, j], image_array[k, c, i+2, j+2]),\n",
    "                    ]\n",
    "                    \n",
    "                    features_three = [\n",
    "                        sigmoid(image_array[k, c, i, j], image_array[k, c, i+2, j+2]),\n",
    "                        sigmoid(image_array[k, c, i, j+2], image_array[k, c, i+2, j]),\n",
    "                    ]\n",
    "\n",
    "                    binary_features.append(features_one+features_two+features_three)\n",
    "            combined_binary_features = tf.concat([tf.convert_to_tensor(binary_features, dtype=tf.float32)], axis=-1)\n",
    "        batch_binary_features.append(combined_binary_features)\n",
    "    tf.cast(batch_binary_features, tf.float32)\n",
    "    return tf.convert_to_tensor(batch_binary_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was for testing. It should not be run in production unless desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_five_binary_features = data_divided.map(lambda x, y: (tf.py_function(graph_based_level_five_transformation, [x[0]], tf.float32), y))\n",
    "# level_five_binary_features = level_five_binary_features.map(lambda x, y: (tf.convert_to_tensor(x), y))\n",
    "level_five_binary_features_iterator = level_five_binary_features.as_numpy_iterator()\n",
    "try:\n",
    "    level_five_binary_features_batch = next(level_five_binary_features_iterator)\n",
    "except StopIteration:\n",
    "    print(\"End of iterator reached.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "level_five_binary_features_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the final step in graph based texture transformation. This step extracts the 64 bit features from each level. The 8 feature images are constructed using these bits.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Incorrect and not needed with new implementation\n",
    "def combine_bit_features(batch):\n",
    "    batch_images = []\n",
    "    for c in range(batch.shape[0]):\n",
    "        image_bits = []\n",
    "        for d in range(batch.shape[1]): # for each division of the image\n",
    "            division_bits = []\n",
    "            for i in range(batch.shape[2]): # For each 64 binary feature list\n",
    "                division_bits.extend(batch[c][d][i])\n",
    "            image_bits.append(division_bits)\n",
    "        batch_images.append(image_bits)\n",
    "    return tf.convert_to_tensor(batch_images, dtype=tf.int32)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_feature_images(binary_features):\n",
    "    dvk_images_batch = []\n",
    "    for c in range(0, binary_features.shape[0]):\n",
    "        dvk_batch_image = []\n",
    "        for d in range(0, binary_features.shape[1]): #each divided image\n",
    "            divided_dvk_image = []\n",
    "            for k in range(0, binary_features.shape[2]): #each 64 bit feature\n",
    "                dvk_feature_images = []\n",
    "                for i in range(0, binary_features.shape[3], 8):\n",
    "                    dvk_image = []\n",
    "                    dvk = 0\n",
    "                    for j in range(0, 8):\n",
    "                        dvk += binary_features[c, d, k, i+j].numpy()*(2**(7-j))\n",
    "                        dvk_image.append(dvk)\n",
    "                    dvk_feature_images.extend(dvk_image)\n",
    "                divided_dvk_image.append(tf.cast(cv2.calcHist([np.array(dvk_feature_images).astype(np.uint8)], None, None, [64], [0, 256]).reshape(-1), dtype=tf.int32)) # histogram of the dvk image, this is done in the paper\n",
    "            dvk_batch_image.append(divided_dvk_image)\n",
    "        dvk_images_batch.append(dvk_batch_image)\n",
    "    return tf.convert_to_tensor(dvk_images_batch, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_graph_based_with_combination(image):\n",
    "    #i, j is top left of kernel\n",
    "    # for 3x3 kernel\n",
    "    batch_binary_features = []\n",
    "\n",
    "    image_array = image\n",
    "    for k in range(0, image_array.shape[0]): #for each image in the batch\n",
    "        image_features = []\n",
    "        for c in range(0, image_array.shape[1]): # for each division of the image\n",
    "            division_features = []\n",
    "            for i in range(0, image_array.shape[2] - 2, 3):\n",
    "                for j in range(0, image_array.shape[3] - 2, 3):\n",
    "                    binary_features = []\n",
    "                    # level 1\n",
    "                    features_one = [\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i, j]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i, j+1]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i+1, j]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i+1, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i+2, j]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i+2, j+1]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i+2, j+2]),\n",
    "                    ]\n",
    "\n",
    "                    features_two = [\n",
    "                        sigmoid(image_array[k, c, i, j], image_array[k, c, i, j+1]),\n",
    "                        sigmoid(image_array[k, c, i, j+1], image_array[k, c, i, j+2]),\n",
    "                        sigmoid(image_array[k, c, i, j+2], image_array[k, c, i+1, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+2], image_array[k, c, i+2, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+2, j+2], image_array[k, c, i+2, j+1]),\n",
    "                        sigmoid(image_array[k, c, i+2, j+1], image_array[k, c, i+2, j]),\n",
    "                        sigmoid(image_array[k, c, i+2, j], image_array[k, c, i+1, j]),\n",
    "                        sigmoid(image_array[k, c, i+1, j], image_array[k, c, i, j])         \n",
    "                    ]\n",
    "                    binary_features.extend(features_one+features_two)\n",
    "\n",
    "                    # level 2\n",
    "                    features_one = [\n",
    "                        sigmoid(image_array[k, c, i, j+1], image_array[k, c, i+1, j]),\n",
    "                        sigmoid(image_array[k, c, i+1, j], image_array[k, c, i+2, j]),\n",
    "                        sigmoid(image_array[k, c, i+2, j], image_array[k, c, i+2, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+2, j+2], image_array[k, c, i+1, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+2], image_array[k, c, i, j+1]),\n",
    "                    ]\n",
    "                    \n",
    "                    features_two = [\n",
    "                        sigmoid(image_array[k, c, i+1, j], image_array[k, c, i, j+1]),\n",
    "                        sigmoid(image_array[k, c, i, j+1], image_array[k, c, i, j+2]),\n",
    "                        sigmoid(image_array[k, c, i, j+2], image_array[k, c, i+2, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+2, j+2], image_array[k, c, i+1, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+2], image_array[k, c, i+2, j+1]),\n",
    "                    ]\n",
    "                    \n",
    "                    features_three = [\n",
    "                        sigmoid(image_array[k, c, i+2, j+1], image_array[k, c, i+1, j]),\n",
    "                        sigmoid(image_array[k, c, i+1, j], image_array[k, c, i, j]),\n",
    "                        sigmoid(image_array[k, c, i, j], image_array[k, c, i, j+2]),\n",
    "                        sigmoid(image_array[k, c, i, j+2], image_array[k, c, i+1, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+2], image_array[k, c, i+2, j+1]),\n",
    "                    ]\n",
    "                \n",
    "                    features_four = [\n",
    "                        sigmoid(image_array[k, c, i+1, j+2], image_array[k, c, i, j+1]),\n",
    "                        sigmoid(image_array[k, c, i, j+1], image_array[k, c, i, j]),\n",
    "                        sigmoid(image_array[k, c, i, j], image_array[k, c, i+2, j]),\n",
    "                        sigmoid(image_array[k, c, i+2, j], image_array[k, c, i+2, j+1]),\n",
    "                        sigmoid(image_array[k, c, i+2, j+1], image_array[k, c, i+1, j+2]),\n",
    "                    ]\n",
    "                    binary_features.extend(features_one+features_two+features_three+features_four)\n",
    "\n",
    "                    # level 3\n",
    "                    features_one = [\n",
    "                        sigmoid(image_array[k, c, i+1, j], image_array[k, c, i, j+1]),\n",
    "                        sigmoid(image_array[k, c, i, j+1], image_array[k, c, i+1, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+2], image_array[k, c, i+2, j+1]),\n",
    "                        sigmoid(image_array[k, c, i+2, j+1], image_array[k, c, i+1, j]),\n",
    "                    ]\n",
    "                    \n",
    "                    features_two = [\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i, j]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i+2, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+1], image_array[k, c, i+1, j]),\n",
    "                    ]\n",
    "                    binary_features.extend(features_one+features_two)\n",
    "\n",
    "\n",
    "                    # level 4\n",
    "                    features_one = [\n",
    "                        sigmoid(image_array[k, c, i+2, j], image_array[k, c, i, j+1]),\n",
    "                        sigmoid(image_array[k, c, i, j+1], image_array[k, c, i+2, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+2, j+2], image_array[k, c, i+2, j]),\n",
    "                    ]\n",
    "                    \n",
    "                    features_two = [\n",
    "                        sigmoid(image_array[k, c, i+1, j], image_array[k, c, i, j+2]),\n",
    "                        sigmoid(image_array[k, c, i, j+2], image_array[k, c, i+2, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+2, j+2], image_array[k, c, i+1, j]),\n",
    "                    ]\n",
    "                    \n",
    "                    features_three = [\n",
    "                        sigmoid(image_array[k, c, i, j], image_array[k, c, i, j+2]),\n",
    "                        sigmoid(image_array[k, c, i, j+2], image_array[k, c, i+2, j+1]),\n",
    "                        sigmoid(image_array[k, c, i+2, j+1], image_array[k, c, i, j]),\n",
    "                    ]\n",
    "                \n",
    "                    features_four = [\n",
    "                        sigmoid(image_array[k, c, i, j], image_array[k, c, i+2, j]),\n",
    "                        sigmoid(image_array[k, c, i+2, j], image_array[k, c, i+1, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j+2], image_array[k, c, i, j]),\n",
    "                    ]\n",
    "                    binary_features.extend(features_one+features_two+features_three+features_four)\n",
    "\n",
    "\n",
    "                    # level 5\n",
    "                    features_one = [\n",
    "                        sigmoid(image_array[k, c, i, j], image_array[k, c, i+2, j]),\n",
    "                        sigmoid(image_array[k, c, i, j+1], image_array[k, c, i+2, j+1]),\n",
    "                        sigmoid(image_array[k, c, i, j+2], image_array[k, c, i+2, j+2]),\n",
    "                    ]\n",
    "                    \n",
    "                    features_two = [\n",
    "                        sigmoid(image_array[k, c, i, j], image_array[k, c, i, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+1, j], image_array[k, c, i+1, j+2]),\n",
    "                        sigmoid(image_array[k, c, i+2, j], image_array[k, c, i+2, j+2]),\n",
    "                    ]\n",
    "                    \n",
    "                    features_three = [\n",
    "                        sigmoid(image_array[k, c, i, j], image_array[k, c, i+2, j+2]),\n",
    "                        sigmoid(image_array[k, c, i, j+2], image_array[k, c, i+2, j]),\n",
    "                    ]\n",
    "\n",
    "                    binary_features.extend(features_one+features_two+features_three)\n",
    "                    division_features.append(binary_features)\n",
    "\n",
    "            image_features.append(division_features)\n",
    "        batch_binary_features.append(image_features)\n",
    "    tf.cast(batch_binary_features, tf.int32)\n",
    "    return tf.convert_to_tensor(batch_binary_features, dtype=tf.int32)\n",
    "    # return tf.convert_to_tensor(combine_bit_features(tf.convert_to_tensor(batch_binary_features, dtype=tf.int32)), dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_binary_features_data = data_divided.map(lambda x, y: (tf.py_function(full_graph_based_with_combination, [x[0]], tf.int32), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_images_data = combined_binary_features_data.map(lambda x, y: (tf.py_function(construct_feature_images, [x], tf.int32), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Texture Transformation Based Facial Expression Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1D Maximum Pooling and PCA Feature Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, there are tons of features for each division of the image. This needs to be toned down. In order to decrease the dimensionality of the data, I utilized 1D maximum pooling. This is a very simple operation. It takes the maximum value in a window and sets that as the value for the window. In the paper, they utilized a 24 window size, but I utilized a 64 window size. This is due to computational complexity and for testing purposes. I will be intrigued to see if this affects the accuracy of my model. This is done in order to decrease the dimensionality of the data. The paper also utilized a PCA feature reduction. This is a very common feature reduction technique. I utilized the PCA feature reduction in order to decrease the dimensionality of the data. The paper utilized 64 features, so I utilized 64 features as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_reduction(image_batch):\n",
    "    batch_pooled_features = []\n",
    "    for k in range(image_batch.shape[0]):\n",
    "        pooled_features = []\n",
    "        for div in range(image_batch.shape[1]):\n",
    "            pooled_feature = []\n",
    "            # feature_reduced_divided_image = []\n",
    "            #Original did 24 size of windows, but I am going to try 64. Partially for experimentation and partially to limit computation time\n",
    "            divided_image_flattened = np.array(image_batch[k][div]).reshape(-1)\n",
    "            for i in range(0, len(divided_image_flattened), 24):\n",
    "                pooled_feature.append(max(divided_image_flattened[i:i+24])/24)\n",
    "            pooled_features.append(pooled_feature)\n",
    "        batch_pooled_features.append(pooled_features)\n",
    "    batch_pca_features = []\n",
    "    for k in range(len(batch_pooled_features)):\n",
    "        division_pca_features = []\n",
    "        for div in range(len(batch_pooled_features[k])):\n",
    "            pooled_features_2d = np.array(batch_pooled_features[k][div]).reshape(-1, 1)\n",
    "            # pca = PCA(n_components=min(pooled_features_2d.shape[0], 128))\n",
    "            pca = PCA(n_components=min(pooled_features_2d.shape[0], pooled_features_2d.shape[1]))\n",
    "            pooled_feature_pca = pca.fit_transform(pooled_features_2d)\n",
    "            pca_features = pooled_feature_pca.flatten()\n",
    "            division_pca_features.append(pca_features)\n",
    "        batch_pca_features.append(division_pca_features)\n",
    "    return tf.convert_to_tensor(batch_pca_features, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Checkpoint 2 Comments\n",
    "During this checkpoint, I completed the graph based texture transformation. This checkpoint, I noticed that my original implementations had some problems. Namely, the dividing image and other graph based transformations. Dividing the image was not correctly working, it was only returning one divided pieces instead of all the divided pieces. The graph based texture transformation was also only doing the one divided piece. Along with that, it was also only doing a single image in the batch. These were oversights/errors that I had to fix this checkpoint. I also started on the next major aspect of the paper, the 1D pooling and pca feature extraction. The only thing that is left is splitting the training and testing data, creating the model, and training the model. I'm hoping that this is the easiest part of the assignment. I'm also hoping that it does not take too long to train, if it does, I may have to slim down my test sets. This will affect the score of my model, but at least I will be able to score it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the model for training\n",
    "This section will have two parts.\n",
    "- The model fitted and trained on the full dataset\n",
    "- The model fitted and trained on a reduced dataset (happy, neutral, and sad) (31 happy images, 30 neutral images, 31 sad images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_reduced_data = feature_images_data.map(lambda x, y: (tf.py_function(feature_reduction, [x], tf.float32), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Test Splitting  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = int(0.8 * len(feature_reduced_data))\n",
    "test_count = int(0.2 * len(feature_reduced_data)+1)\n",
    "print(train_count, test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = feature_reduced_data.take(train_count)\n",
    "test_data = feature_reduced_data.skip(train_count).take(test_count)\n",
    "train_data_iterator = train_data.as_numpy_iterator()\n",
    "test_data_iterator = test_data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is for the reduced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for batch in data:\n",
    "        print(batch)\n",
    "        features.append(batch[0])\n",
    "        labels.append(batch[1])\n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code cell will run all preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_and_labels_extracted = extract_features(train_data)\n",
    "train_features = train_feature_and_labels_extracted[0]\n",
    "train_labels = train_feature_and_labels_extracted[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can load the data from the npz file. This file was saved by me earlier, and contains all of the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = np.load('train_data_working.npz')\n",
    "reshaped_features = loaded_data['features']\n",
    "train_labels = loaded_data['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code cell reshapes the data, this is only necessary if you did not load the data in from npz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples, num_channels, height, width = train_features.shape\n",
    "reshaped_features = train_features.reshape(num_samples * num_channels, -1)\n",
    "train_labels = train_labels.ravel()\n",
    "train_labels.shape, reshaped_features.shape, type(train_labels), type(reshaped_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell saves the preprocessed training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('train_data_working_1.npz', features=reshaped_features, labels=train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell utilizes a Grid Search to get the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC()\n",
    "grid_search = GridSearchCV(\n",
    "    svm_model,\n",
    "    param_grid={\"C\": np.logspace(-4, 4, 20), \"gamma\": np.logspace(-4, 4, 20), \"kernel\": ['linear', 'rbf', \"poly\"]},\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "grid_search.fit(reshaped_features, train_labels)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best C:\", best_params['C'])\n",
    "print(\"Best gamma:\", best_params['gamma'])\n",
    "print(\"Best kernel:\", best_params['kernel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell creates the model and fits it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel=best_params['kernel'], C=best_params['C'], gamma=best_params['gamma'])\n",
    "svm_model.fit(reshaped_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validate the model and display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_scores = cross_validate(svm_model, reshaped_features, train_labels, cv=5, scoring='accuracy', return_train_score=True)\n",
    "pd.DataFrame(svm_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix for more visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_confusion_matrix = confusion_matrix(train_labels, svm_model.predict(reshaped_features))\n",
    "training_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the features from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature_and_labels_extracted = extract_features(test_data)\n",
    "test_features = test_feature_and_labels_extracted[0]\n",
    "test_labels = test_feature_and_labels_extracted[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can load the test data from the npz file. This file was saved by me earlier, and contains all of the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loaded_data = np.load('test_data_working.npz')\n",
    "reshaped_test_features = test_loaded_data['features']\n",
    "test_labels = loaded_data['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples, num_channels, height, width = test_features.shape\n",
    "reshaped_test_features = test_features.reshape(num_samples * num_channels, -1)\n",
    "test_labels = test_labels.ravel()\n",
    "test_labels.shape, reshaped_test_features.shape, type(test_labels), type(reshaped_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('test_data_working.npz', features=reshaped_test_features, labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, scoring the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model.score(reshaped_test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My final score was typically around 40-50%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
